{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peThRjgXJeZY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.combine import SMOTETomek\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define correlation function\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold:  # Interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # Getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading dataset...\")\n",
        "dataset = pd.read_csv('/content/mydrive/MyDrive/PCOS_extended_dataset.csv')\n",
        "\n",
        "# Replace incorrect value in 'II beta-HCG(mIU/mL)'\n",
        "print(\"Replacing incorrect values...\")\n",
        "dataset['II    beta-HCG(mIU/mL)'] = dataset['II    beta-HCG(mIU/mL)'].replace('1.99.', '1.99')\n",
        "\n",
        "X = dataset.drop('PCOS (Y/N)', axis=1)\n",
        "y = dataset['PCOS (Y/N)']\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Print the shape and class distribution of the original data\n",
        "print(\"Original data shape:\")\n",
        "print(\"X_imputed shape:\", X_imputed.shape)\n",
        "print(\"y value counts:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Calculate mutual information scores\n",
        "mutual_info_scores = mutual_info_classif(X_imputed, y)\n",
        "\n",
        "# Randomly select fewer features for feature selection\n",
        "k = 20  # Number of top features to select\n",
        "top_indices = np.argsort(mutual_info_scores)[::-1][:k]\n",
        "selected_features = X.iloc[:, top_indices]\n",
        "\n",
        "# Define feature selection methods\n",
        "feature_selection_methods = {\n",
        "    'Pearson Correlation': X.corr(),\n",
        "    'Mutual Information': selected_features\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "for method_name, scores in feature_selection_methods.items():\n",
        "    print(f\"Using {method_name} for feature selection...\")\n",
        "\n",
        "    # Initialize KFold and lists for evaluation metrics\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    accuracies, sensitivities, specificities, f1_scores, roc_auc_scores = [], [], [], [], []\n",
        "\n",
        "    # Perform 10-fold cross-validation\n",
        "    for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "        print(f\"\\nFold {fold+1}:\")\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Apply SMOTETomek\n",
        "        smote = SMOTETomek(random_state=0)\n",
        "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "        if method_name == 'Pearson Correlation':\n",
        "            # Pearson correlation-based feature selection\n",
        "            X_train_smote = pd.DataFrame(X_train_smote)\n",
        "            corr_features = correlation(X_train_smote, 0.80)\n",
        "            X_train_selected = X_train_smote.drop(corr_features, axis=1)\n",
        "            X_test_selected = X_test.drop(corr_features, axis=1)\n",
        "        else:\n",
        "            # Mutual information-based feature selection\n",
        "            X_train_selected = X_train_smote.iloc[:, top_indices]\n",
        "            X_test_selected = X_test.iloc[:, top_indices]\n",
        "\n",
        "        # Handle missing values\n",
        "        X_train_imputed = imputer.fit_transform(X_train_selected)\n",
        "        X_test_imputed = imputer.transform(X_test_selected)\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "        X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "        # First layer classifiers\n",
        "        classifiers_first_layer = {\n",
        "            'Naive Bayes': GaussianNB(),\n",
        "            'Random Forest': RandomForestClassifier()\n",
        "        }\n",
        "        predictions_first_layer = []\n",
        "        for name, clf in classifiers_first_layer.items():\n",
        "            clf.fit(X_train_scaled, y_train_smote)\n",
        "            predictions_first_layer.append(clf.predict_proba(X_test_scaled)[:, 1])\n",
        "\n",
        "        X_test_combined_first_layer = np.column_stack(predictions_first_layer)\n",
        "\n",
        "        # Second layer classifiers\n",
        "        classifiers_second_layer = {'Logistic Regression': LogisticRegression()}\n",
        "        predictions_second_layer = []\n",
        "        for name, clf in classifiers_second_layer.items():\n",
        "            clf.fit(X_test_combined_first_layer, y_test)\n",
        "            predictions_second_layer.append(clf.predict_proba(X_test_combined_first_layer)[:, 1])\n",
        "\n",
        "        X_test_combined_second_layer = np.column_stack(predictions_second_layer)\n",
        "\n",
        "        # Train meta layer classifier\n",
        "        mlp_parameters = {\n",
        "            'hidden_layer_sizes': [(100,), (50, 50), (50,)],\n",
        "            'alpha': [0.0001, 0.01, 0.001],\n",
        "            'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "        }\n",
        "        meta_classifier = GridSearchCV(MLPClassifier(max_iter=1000, early_stopping=True, solver='adam', learning_rate='adaptive'),\n",
        "                                       mlp_parameters, cv=5)\n",
        "        meta_classifier.fit(X_test_combined_second_layer, y_test)\n",
        "        best_mlp = meta_classifier.best_estimator_\n",
        "\n",
        "        # Make predictions using stacked ensemble model\n",
        "        y_pred_stacked_ensemble = best_mlp.predict(X_test_combined_second_layer)\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred_stacked_ensemble)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred_stacked_ensemble).ravel()\n",
        "        sensitivity = tp / (tp + fn)\n",
        "        specificity = tn / (tn + fp)\n",
        "        f1 = f1_score(y_test, y_pred_stacked_ensemble)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_stacked_ensemble)\n",
        "\n",
        "        # Append metrics\n",
        "        accuracies.append(accuracy)\n",
        "        sensitivities.append(sensitivity)\n",
        "        specificities.append(specificity)\n",
        "        f1_scores.append(f1)\n",
        "        roc_auc_scores.append(roc_auc)\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    avg_sensitivity = np.mean(sensitivities)\n",
        "    avg_specificity = np.mean(specificities)\n",
        "    avg_f1_score = np.mean(f1_scores)\n",
        "    avg_roc_auc_score = np.mean(roc_auc_scores)\n",
        "\n",
        "    print(f\"\\nFinal Average Results for {method_name}:\")\n",
        "    print(f\"Accuracy: {avg_accuracy}, Sensitivity: {avg_sensitivity}, Specificity: {avg_specificity}\")\n",
        "    print(f\"F1-score: {avg_f1_score}, ROC AUC: {avg_roc_auc_score}\")\n",
        "\n",
        "    # Plot loss curve\n",
        "    plt.plot(best_mlp.loss_curve_, label=f'{method_name}')\n",
        "\n",
        "plt.title('Train Loss Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}